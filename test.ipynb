{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ea8a0f",
   "metadata": {},
   "source": [
    "# Primo caso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab74370",
   "metadata": {},
   "source": [
    "- pip install scikit-learn\n",
    "- pip install sentence-transformers\n",
    "- pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7920a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libreria che consente la rappresentazione vettoriale (embedded) di frasi anziché parole\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Libreria per calcolare la similarità coseno tra vettori (la similiarità coseno misura quanto due vettori sono simili)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Libreria per il rilevamento della lingua del testo\n",
    "from langdetect import detect\n",
    "\n",
    "# Carica modello multilingua potente che comprende l'italiano\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Lista statica di API con descrizioni ed endpoint\n",
    "api_catalog = [\n",
    "    {\n",
    "        \"descrizione\": \"Creazione nuovo finanziamento. Creazione per tipo e ndg\",\n",
    "        \"endpoint\": \"api/finanziamento\",\n",
    "        \"verbo\": \"POST\",\n",
    "    },\n",
    "    {\n",
    "        \"descrizione\": \"Ricerca un finanziamento esistente. Ricerca per tipo e ndg\",\n",
    "        \"endpoint\": \"api/finanziamento&tipo=mutuo&ndg=123456\",\n",
    "        \"verbo\": \"GET\",\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_api(testo_input, soglia_similarita=0.5):\n",
    "    try:\n",
    "        # Verifica che la lingua sia italiana\n",
    "        if detect(testo_input) != \"it\":\n",
    "            return \"Per favore fornisci il testo in italiano.\"\n",
    "\n",
    "        # Calcola embedding del testo utente\n",
    "        embedding_input = model.encode([testo_input])\n",
    "\n",
    "        migliori_match = {\"endpoint\": None, \"score\": 0.0}\n",
    "\n",
    "        # Confronta con le descrizioni delle API\n",
    "        for api in api_catalog:\n",
    "            # Calcola embedding della descrizione dell'API\n",
    "            embedding_descrizione = model.encode([api[\"descrizione\"]])\n",
    "            # Calcola la similarità coseno tra l'input e la descrizione dell'API\n",
    "            sim = cosine_similarity(embedding_input, embedding_descrizione)[0][0]\n",
    "\n",
    "            # Aggiorna il miglior match se la similarità è maggiore della soglia\n",
    "            if sim > migliori_match[\"score\"]:\n",
    "                migliori_match = {\"endpoint\": api[\"endpoint\"], \"score\": sim}\n",
    "\n",
    "        # Controlla se il miglior match supera la soglia di similarità\n",
    "        if migliori_match[\"score\"] >= soglia_similarita:\n",
    "            return f\"{migliori_match['endpoint']}\"\n",
    "        else:\n",
    "            return \"La richiesta non trova corrispondenza con nessuna API. Riprova.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Errore durante l'elaborazione: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fdb0f9",
   "metadata": {},
   "source": [
    "# Test primo caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf43d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "esempi_richiesta = [\n",
    "    \"cercami i finanziamenti dell'ndg 123456\",\n",
    "    \"voglio avviare un nuovo finanziamento\",\n",
    "    \"mi cerchi un finanziamento\",\n",
    "    \"ho bisogno di un mutuo per la casa\",\n",
    "    \"vado a comprarmi una pizza\",\n",
    "    \"mi crei un finanziamento con ndg 123456 e tipo mutuo\",\n",
    "]\n",
    "\n",
    "for richiesta in esempi_richiesta:\n",
    "    print(f\"  Richiesta utente: {richiesta}\")\n",
    "    print(f\"Endpoint associato: {get_api(richiesta)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0628d17c",
   "metadata": {},
   "source": [
    "# Secondo caso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f50adb",
   "metadata": {},
   "source": [
    "- pip install spacy\n",
    "- python -m spacy download it_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915649c0",
   "metadata": {},
   "source": [
    "# Importo librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02975895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libreria per l'elaborazione del linguaggio naturale\n",
    "import spacy\n",
    "# Libreria per operazioni numeriche e matriciali\n",
    "import numpy as np\n",
    "# Libreria per il modello di classificazione\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Libreria che consente la rappresentazione vettoriale (embedded) di frasi anziché parole\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "# Libreria per calcolare la similarità coseno tra vettori (la similiarità coseno misura quanto due vettori sono simili)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Libreria per modelli di trasformatori (transformers)\n",
    "from transformers import pipeline \n",
    "# Disabilita i warning di transformers\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "# Libreria per gestire tensori e modelli di deep learning\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8802331",
   "metadata": {},
   "source": [
    "# Addestramento machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48469fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\n",
    "    # ==== GET ====\n",
    "    \"cerca\", \"cercami\", \"fai una ricerca\", \"esegui una ricerca\",\n",
    "    \"trova\", \"trovami\", \"rintraccia\", \"identifica\",\n",
    "    \"recupera\", \"recuperami\", \"ottieni dati\", \"estrai informazioni\",\n",
    "    \"mostra\", \"mostrami\", \"fammi vedere\", \"visualizza\",\n",
    "    \"leggi\", \"leggimi\", \"accedi ai dati\", \"ottieni i dati\",\n",
    "    \"visualizza\", \"visualizzami\", \"rendi visibile\", \"presenta\",\n",
    "    \"vedi\", \"vedimi\", \"guarda i dati\", \"dammi una vista\",\n",
    "    \"estrai\", \"estraimi\", \"scarica dati\", \"porta fuori dati\",\n",
    "    \"accedi\", \"accedimi\", \"entra nei dati\", \"consulta\",\n",
    "\n",
    "    # ==== POST ====\n",
    "    \"crea\", \"creami\", \"genera nuovo\", \"costruisci un nuovo\",\n",
    "    \"inserisci\", \"inseriscimi\", \"aggiungi\", \"carica nuovi dati\",\n",
    "    \"richiedi\", \"richiedimi\", \"fai una richiesta\", \"manda una richiesta\",\n",
    "    \"apri\", \"aprimi\", \"avvia una nuova pratica\", \"inizia procedura\",\n",
    "    \"avvia\", \"avviami\", \"dai inizio\", \"comincia processo\",\n",
    "    \"registra\", \"registrami\", \"salva nuovo\", \"archivia dati\",\n",
    "    \"attiva\", \"attivami\", \"metti in funzione\", \"abilita\",\n",
    "    \"compila\", \"compilami\", \"riempi i dati\", \"completa il modulo\",\n",
    "\n",
    "    # ==== PUT ====\n",
    "    \"aggiorna\", \"aggiornami\", \"fai un aggiornamento\", \"modifica con nuovi dati\",\n",
    "    \"modifica\", \"modificami\", \"cambia i dati\", \"rivedi i valori\",\n",
    "    \"correggi\", \"correggimi\", \"sistema dati\", \"risolvi errori\",\n",
    "    \"rivedi\", \"rivedimi\", \"verifica e modifica\", \"ritocca\",\n",
    "    \"sostituisci\", \"sostituiscimi\", \"cambia con altro\", \"scambia contenuto\",\n",
    "    \"ricalcola\", \"ricalcolami\", \"rifai i conti\", \"esegui nuovo calcolo\",\n",
    "\n",
    "    # ==== DELETE ====\n",
    "    \"elimina\", \"eliminami\", \"cancella definitivamente\", \"rimuovi per sempre\",\n",
    "    \"cancella\", \"cancellami\", \"butta via\", \"togli dai dati\",\n",
    "    \"rimuovi\", \"rimuovimi\", \"escludi\", \"levami dai dati\",\n",
    "    \"revoca\", \"revocami\", \"invalida\", \"annulla autorizzazione\",\n",
    "    \"annulla\", \"annullami\", \"ferma l’operazione\", \"interrompi processo\",\n",
    "    \"disattiva\", \"disattivami\", \"spegni\", \"rendi inattivo\"\n",
    "]\n",
    "\n",
    "y_train = [\n",
    "    # ==== GET ====\n",
    "    *[\"GET\"]*36,\n",
    "    # ==== POST ====\n",
    "    *[\"POST\"]*32,\n",
    "    # ==== PUT ====\n",
    "    *[\"PUT\"]*24,\n",
    "    # ==== DELETE ====\n",
    "    *[\"DELETE\"]*24\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900bc43",
   "metadata": {},
   "source": [
    "Opzione 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "645fbabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il modello italiano\n",
    "nlp = spacy.load(\"it_core_news_md\")\n",
    "\n",
    "#metodo per trasformare x_train che contiene frasi in vettori numerici\n",
    "def vectorizza(frasi):\n",
    "    return np.array([nlp(frase).vector for frase in frasi])\n",
    "\n",
    "# Vettorizza il training set\n",
    "X_vect = vectorizza(X_train)\n",
    "\n",
    "# Definisci il classificatore\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Allena il classificatore\n",
    "clf.fit(X_vect, y_train)\n",
    "\n",
    "# Metodo per estrarre verbo e complemento oggetto da una frase\n",
    "def estrai_verbo_oggetto(frase: str, include_oggetto: bool = False):\n",
    "    # Analizza la frase con spaCy\n",
    "    doc = nlp(frase)\n",
    "    risultati = []\n",
    "    # Itera sui token della frase\n",
    "    for token in doc:\n",
    "        # Verbi\n",
    "        if token.pos_ == \"VERB\":\n",
    "            # Aggiungi il verbo alla lista dei risultati\n",
    "            risultati.append((\"VERBO\", token.text))\n",
    "        # Complemento oggetto (solo se richiesto dal flag)\n",
    "        if include_oggetto and token.dep_ == \"obj\":\n",
    "            # Aggiungi l'oggetto alla lista dei risultati\n",
    "            risultati.append((\"OGGETTO\", token.text))\n",
    "    return risultati\n",
    "\n",
    "def classifica_http(testo_input: str, include_oggetto: bool = False):\n",
    "    # Estraggo le caratteristiche del verbo (e oggetto se richiesto)\n",
    "    caratteristiche_verbo = estrai_verbo_oggetto(testo_input, include_oggetto)\n",
    "    if include_oggetto:\n",
    "        # Estraggo sia la parola del verbo che dell'oggetto (escludendo etichetta e posizioni)\n",
    "        verbo = [v[1] for v in caratteristiche_verbo if v[0] == \"VERBO\" or v[0] == \"OGGETTO\"]\n",
    "    else:\n",
    "        # Estraggo solo la parola del verbo (escludendo etichetta e posizioni)\n",
    "        verbo = [v[1] for v in caratteristiche_verbo if v[0] == \"VERBO\"]\n",
    "    # Vettorizzazione\n",
    "    verbo_vect = vectorizza(verbo)\n",
    "    # Predizione\n",
    "    verbo_predetto = clf.predict(verbo_vect)[0]\n",
    "    # Probabilità per tutte le classi\n",
    "    probs = clf.predict_proba(verbo_vect)[0]   # array 1D tipo [0.05, 0.10, 0.82, 0.03]\n",
    "    # Indice della classe predetta\n",
    "    verbo_predetto_indice = clf.classes_.tolist().index(verbo_predetto)\n",
    "    # Probabilità della classe predetta\n",
    "    score_verbo_predetto = probs[verbo_predetto_indice]\n",
    "    print(\"--- ML\")\n",
    "    print(f\"       Verbo estratto: {verbo}\")\n",
    "    print(f\"  Verbo http predetto: {verbo_predetto}\")\n",
    "    print(f\"               Classi: {clf.classes_}\")\n",
    "    print(f\"          Probabilità: {probs}\")\n",
    "    print(f\"  Indice della classe: {verbo_predetto_indice}\")\n",
    "    print(f\"Probabilità del verbo: {score_verbo_predetto}\")\n",
    "    #esempio\n",
    "    #   Verbo http predetto       → 'POST'\n",
    "    #   Classi                    → ['DELETE', 'GET', 'POST', 'PUT']\n",
    "    #   Probabilità               → [0.05, 0.10, 0.82, 0.03]  # stesso ordine\n",
    "    #   Indice della classe       → 2  (perché 'POST' è il 3° elemento)\n",
    "    #   Probabilità del verbo     → verbo_probabilita[2] = 0.82\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e3ea94",
   "metadata": {},
   "source": [
    "Opzione 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e8c37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modello di embedding\n",
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Calcolo gli embeddings dei tuoi esempi di training\n",
    "X_emb = embedding_model.encode(X_train, convert_to_tensor=True)\n",
    "\"\"\" \n",
    "# print(X_emb)\n",
    "tensor([[ 0.012,  0.034, ..., -0.021],\n",
    "        [ 0.020,  0.040, ..., -0.010],\n",
    "        [ 0.015,  0.028, ..., -0.018],\n",
    "        ...,\n",
    "        [-0.012, 0.033, ..., 0.019]])\n",
    "# print(\"Shape:\", X_emb.shape)\n",
    "Shape: torch.Size([116, 384]) \n",
    "\"\"\"\n",
    "\n",
    "# Zero-shot fallback: \n",
    "# - zero-shot significa che si usa un modello pre-addestrato, che non necessita di addestramento sui tuoi esempi, per classificare i miei esempi\n",
    "# - fallback perché uso prima un metodo principale e se la confidenza è bassa uso questo\n",
    "# In poche parole, serve solo se vuoi gestire verbi/frasi molto fuori dai tuoi esempi\n",
    "\n",
    "# Uso il modello BART di Facebook addestrato su MNLI (Multi-Genre Natural Language Inference)\n",
    "# MNLI è un dataset di inferenza testuale, dove il modello impara a capire se una frase implica, contraddice o è neutrale rispetto a un'altra frase\n",
    "zero_shot_model = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\"\n",
    ")\n",
    "\n",
    "# Etichette HTTP\n",
    "http_labels = [\"GET\", \"POST\", \"PUT\", \"DELETE\"]\n",
    "\n",
    "def classifica_http_2(testo_input: str, include_oggetto: bool = False, top_k: int = 3, fallback_soglia: float = 0.65):\n",
    "    print(\"--- NLP\")\n",
    "    \"\"\" \n",
    "    ESEMPIO\n",
    "    \"butta via i documenti\"\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== Step 1: Estrazione del verbo dall’input ===\")\n",
    "    caratteristiche_verbo = estrai_verbo_oggetto(testo_input, include_oggetto)\n",
    "    print(\"        Token estratti:\", caratteristiche_verbo)\n",
    "    if include_oggetto:\n",
    "        # Estraggo sia la parola del verbo che dell'oggetto (escludendo etichetta e posizioni)\n",
    "        verbo = [v[1] for v in caratteristiche_verbo if v[0] == \"VERBO\" or v[0] == \"OGGETTO\"]\n",
    "    else:\n",
    "        # Estraggo solo la parola del verbo (escludendo etichetta e posizioni)\n",
    "        verbo = [v[1] for v in caratteristiche_verbo if v[0] == \"VERBO\"]\n",
    "    print(\"        Verbo estratto:\", verbo)\n",
    "    \"\"\" \n",
    "    Token estratti: [('VERBO','butta')]\n",
    "    Verbo estratto: ['butta'] \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n=== Step 2: Calcolo dell’embedding del verbo estratto ===\")\n",
    "    verbo_emb = embedding_model.encode(verbo, convert_to_tensor=True)\n",
    "    print(\"        Verbo embedded:\", verbo_emb.shape)\n",
    "    \"\"\" \n",
    "    Verbo embedded: (1, 384)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n=== Step 3: Calcolo della similarità coseno con gli esempi di training ===\")\n",
    "    cos_scores = util.cos_sim(verbo_emb, X_emb)[0] \n",
    "    print(\"     Similarità coseno:\", cos_scores)\n",
    "    \"\"\" \n",
    "    Similarità coseno: [0.45, 0.12, 0.08, 0.78, ...]\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n=== Step 4: Selezione dei top_k esempi più simili ===\")\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "    preds = [y_train[i] for i in top_results] \n",
    "    verbo_predetto = preds[0] \n",
    "    confidenza = float(cos_scores[top_results[0]])\n",
    "    print(\"          Indici top_k:\", top_results)\n",
    "    print(\"      Top_k similarità:\", cos_scores[top_results])\n",
    "    print(\"          Classi top_k:\", preds)\n",
    "    \"\"\" \n",
    "    Indici top_k: [3, 6, 0]\n",
    "    Valori top_k similarità: [0.78, 0.65, 0.45]\n",
    "    Classi top_k: ['DELETE', 'GET', 'GET']\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n=== Step 5: Predizione basata sulla classe più frequente ===\")\n",
    "    # conta quante volte compare ogni classe nei top_k\n",
    "    counts = {label: preds.count(label) for label in set(preds)} \n",
    "    # perché prendere la classe con il conteggio massimo?\n",
    "    # vantaggio:\n",
    "    # - robustezza contro outlier: se uno dei top_k è un outlier\n",
    "    # svantaggio:\n",
    "    # - non considera la similarità: potrei avere 2 esempi \"GET\" con similarità 0.45 e 0.44, e 1 esempio \"DELETE\" con similarità 0.78\n",
    "    verbo_predetto_2 = max(counts, key=counts.get)\n",
    "    print(\"      Conteggio classi:\", counts)\n",
    "    print(\"    Classe più quotata:\", verbo_predetto)\n",
    "    \"\"\" \n",
    "    Conteggio classi: {'DELETE': 1, 'GET': 2}\n",
    "    Classe più quotata: GET\n",
    "    # print(\"Similarità max:\", confidenza)\n",
    "    Confidenza (similarità max): 0.78\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n=== Step 6: Calcolo delle probabilità normalizzate per ogni classe ===\")\n",
    "    probs_dict = {}\n",
    "    for label in http_labels:\n",
    "        # prendo tutti i top_results che hanno questa label\n",
    "        label_indices = [i for i in top_results if y_train[i] == label]\n",
    "        if label_indices:\n",
    "            # converto cos_scores in numpy solo se è un tensor\n",
    "            cos_scores_np = cos_scores.cpu().detach().numpy() if isinstance(cos_scores, torch.Tensor) else cos_scores\n",
    "            # media delle similarità per questa classe\n",
    "            probs_dict[label] = float(np.mean(cos_scores_np[label_indices]))\n",
    "        else:\n",
    "            probs_dict[label] = 0.0\n",
    "    print(\"  Probabilità non norm:\", probs_dict)\n",
    "    # Normalizzo in modo che la somma sia 1\n",
    "    total = sum(probs_dict.values())\n",
    "    if total > 0:\n",
    "        probs = [probs_dict[label]/total for label in http_labels]\n",
    "    else:\n",
    "        # fallback uniforme se total = 0\n",
    "        probs = [1/len(http_labels)]*len(http_labels)\n",
    "    print(\"      Probabilità norm:\", probs)\n",
    "    \"\"\" \n",
    "    Probabilità non normalizzate: {'GET': 0.285, 'POST': 0.0, 'PUT': 0.0, 'DELETE': 0.78}\n",
    "    Probabilità normalizzate: [0.27, 0.0, 0.0, 0.73]\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n=== Step 7: Fallback zero-shot se la confidenza è bassa ===\")\n",
    "    if confidenza < fallback_soglia:\n",
    "        zero_shot_res = zero_shot_model(testo_input, candidate_labels=http_labels)\n",
    "        verbo_predetto_zero_shot = zero_shot_res['labels'][0]\n",
    "        probs_zero_shot = [zero_shot_res['scores'][zero_shot_res['labels'].index(label)] for label in http_labels]\n",
    "        print(\"        Caso zero shot\")\n",
    "        print(\"                Classi:\", zero_shot_res['labels'])\n",
    "        print(\"           Probabilità:\", zero_shot_res['scores'])\n",
    "        print(\"         Classe finale:\", verbo_predetto_zero_shot)\n",
    "        if zero_shot_res['scores'][0] > confidenza:\n",
    "            verbo_predetto = verbo_predetto_zero_shot\n",
    "            probs = probs_zero_shot\n",
    "\n",
    "\n",
    "    print(\"\\n--- Step 8: Risultato finale ---\")\n",
    "    print(\"       Classe predetta:\", verbo_predetto)\n",
    "    print(\"           Probabilità:\", probs)\n",
    "    \"\"\" \n",
    "    Classe predetta: GET\n",
    "    Probabilità di tutte le classi: [0.27, 0.0, 0.0, 0.73]\n",
    "    \"\"\"\n",
    "\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e154ba",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b112c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodo per analizzare il testo e suddividerlo in frasi\n",
    "\"\"\" Il metodo riconosce più frasi separate da punteggiatura, invece, ad esempio, non riconosce invece frasi congiunte da \"e\" o \"poi\" \"\"\"\n",
    "def analizza_frasi(testo: str):\n",
    "    # Analizza la frase con spaCy\n",
    "    doc = nlp(testo)\n",
    "    # Estrai le frasi dal testo\n",
    "    frasi = [sent.text.strip() for sent in doc.sents] \n",
    "    print(f\"       Frasi estratte: {frasi}\")\n",
    "    return len(frasi), frasi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0687a6",
   "metadata": {},
   "source": [
    "# Api da individuare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "281f1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista statica di API con descrizioni ed endpoint\n",
    "api_catalog = [\n",
    "    {\n",
    "        \"descrizione\": \"Creazione nuovo finanziamento. Creazione per tipo e ndg\",\n",
    "        \"endpoint\": \"api/finanziamento\",\n",
    "        \"verbo_http\": \"POST\"\n",
    "    },\n",
    "    {\n",
    "        \"descrizione\": \"Ricerca un finanziamento esistente. Ricerca per tipo e ndg\",\n",
    "        \"endpoint\": \"api/finanziamento?tipo=mutuo&ndg=123456\",\n",
    "        \"verbo_http\": \"GET\"\n",
    "    },\n",
    "    {\n",
    "        \"descrizione\": \"Cancellazione finanziamento esistente. Cancellazione per ndg\",\n",
    "        \"endpoint\": \"api/finanziamento?ndg=123456\",\n",
    "        \"verbo_http\": \"DELETE\"\n",
    "    },\n",
    "    {\n",
    "        \"descrizione\": \"Aggiornamento finanziamento esistente. Aggiornamento per ndg\",\n",
    "        \"endpoint\": \"api/finanziamento?ndg=123456\",\n",
    "        \"verbo_http\": \"PUT\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f620f",
   "metadata": {},
   "source": [
    "# Algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "518d980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica modello multilingua potente che comprende l'italiano\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def get_api_2(testo_input, include_oggetto=False, ml_weight=0.5, nlp_weight=0.5, soglia_similarita=0.5):\n",
    "    try:\n",
    "        print(f\"     Richiesta utente: {testo_input}\")\n",
    "\n",
    "        # Verifica che la richiesta contenga una sola frase\n",
    "        num_frasi, lista_frasi = analizza_frasi(testo_input)\n",
    "        if num_frasi > 1:\n",
    "            return f\"                       La richiesta contiene {num_frasi} frasi. Per favore invia una sola frase alla volta. Frasi rilevate: {lista_frasi}\"\n",
    "        \n",
    "        # Recupera le probabilità per ogni verbo HTTP\n",
    "        probs = classifica_http_2(testo_input, include_oggetto)\n",
    "\n",
    "        # Calcola embedding del testo utente\n",
    "        embedding_input = model.encode([testo_input])\n",
    "\n",
    "        migliore_match = {\"endpoint\": None, \"verbo_http\": None, \"score\": 0.0}\n",
    "        migliore_match_composito = {\"endpoint\": None, \"verbo_http\": None, \"score\": 0.0}\n",
    "\n",
    "        # Confronta con le descrizioni delle API\n",
    "        for api in api_catalog:\n",
    "\n",
    "            # Calcola embedding della descrizione dell'API\n",
    "            embedding_api = model.encode([api[\"descrizione\"]])\n",
    "\n",
    "            # Calcola la similarità coseno tra l'input e la descrizione dell'API\n",
    "            sim = cosine_similarity(embedding_input, embedding_api)[0][0]\n",
    "\n",
    "            # Aggiorna il miglior match se la similarità è maggiore della soglia\n",
    "            if sim > migliore_match[\"score\"]:\n",
    "                migliore_match = {\"endpoint\": api[\"endpoint\"], \"verbo_http\": api[\"verbo_http\"], \"score\": sim}\n",
    "\n",
    "            \n",
    "            # Combina i due score (similarità e probabilità verbo) con pesi alpha e beta\n",
    "            verbo_indice = clf.classes_.tolist().index(api[\"verbo_http\"])\n",
    "            score_verbo = probs[verbo_indice]\n",
    "            sim_composito = ml_weight * score_verbo + nlp_weight * sim\n",
    "            if sim_composito > migliore_match_composito[\"score\"]:\n",
    "                migliore_match_composito = {\"endpoint\": api[\"endpoint\"], \"verbo_http\": api[\"verbo_http\"], \"score\": sim_composito}\n",
    "            \n",
    "\n",
    "        print(\"--- NLP 2\")\n",
    "        print(f\"    Similarità coseno: {migliore_match}\")\n",
    "        print(\"--- ML + NLP\")\n",
    "\n",
    "        # Controlla se il miglior match supera la soglia di similarità\n",
    "        if migliore_match_composito[\"score\"] >= soglia_similarita:\n",
    "            return f\"                       {migliore_match_composito}\"\n",
    "        else:\n",
    "            return \"                       La richiesta non trova corrispondenza con nessuna API. (score: \" + str(migliore_match_composito[\"score\"]) + \")\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Errore durante l'elaborazione: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97063346",
   "metadata": {},
   "source": [
    "# Test secondo caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32bbbab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "     Richiesta utente: cercami i finanziamenti dell'ndg 123456\n",
      "       Frasi estratte: [\"cercami i finanziamenti dell'ndg 123456\"]\n",
      "--- NLP\n",
      "=== Step 1: Estrazione del verbo dall’input ===\n",
      "        Token estratti: [('VERBO', 'cercami')]\n",
      "        Verbo estratto: ['cercami']\n",
      "\n",
      "=== Step 2: Calcolo dell’embedding del verbo estratto ===\n",
      "        Verbo embedded: torch.Size([1, 384])\n",
      "\n",
      "=== Step 3: Calcolo della similarità coseno con gli esempi di training ===\n",
      "     Similarità coseno: tensor([0.8232, 1.0000, 0.7210, 0.7071, 0.9166, 0.8786, 0.7286, 0.7817, 0.6888,\n",
      "        0.6574, 0.5152, 0.7403, 0.8221, 0.7070, 0.7815, 0.8031, 0.6185, 0.8672,\n",
      "        0.4677, 0.4708, 0.8031, 0.7944, 0.7171, 0.6710, 0.8125, 0.7034, 0.5087,\n",
      "        0.7465, 0.7911, 0.7205, 0.3615, 0.4202, 0.7508, 0.7308, 0.4171, 0.6253,\n",
      "        0.8061, 0.7600, 0.4655, 0.3658, 0.7918, 0.7920, 0.7830, 0.2833, 0.7674,\n",
      "        0.8311, 0.6489, 0.4917, 0.8187, 0.4795, 0.4035, 0.4821, 0.8237, 0.7713,\n",
      "        0.5737, 0.5155, 0.7745, 0.7613, 0.5418, 0.3232, 0.6819, 0.6700, 0.6564,\n",
      "        0.7017, 0.5029, 0.7241, 0.3758, 0.4836, 0.6232, 0.6929, 0.5541, 0.1972,\n",
      "        0.5581, 0.6607, 0.2970, 0.5017, 0.6563, 0.6866, 0.2667, 0.4032, 0.7614,\n",
      "        0.7230, 0.4944, 0.7050, 0.5940, 0.5929, 0.4654, 0.4960, 0.4573, 0.4008,\n",
      "        0.7527, 0.4849, 0.5847, 0.6133, 0.6113, 0.4052, 0.3724, 0.5538, 0.6794,\n",
      "        0.5090, 0.6258, 0.6089, 0.7710, 0.5170, 0.5794, 0.5921, 0.6204, 0.4133,\n",
      "        0.6886, 0.8238, 0.3756, 0.3083, 0.6815, 0.6983, 0.8423, 0.5608])\n",
      "\n",
      "=== Step 4: Selezione dei top_k esempi più simili ===\n",
      "          Indici top_k: tensor([1, 4, 5])\n",
      "      Top_k similarità: tensor([1.0000, 0.9166, 0.8786])\n",
      "          Classi top_k: ['GET', 'GET', 'GET']\n",
      "\n",
      "=== Step 5: Predizione basata sulla classe più frequente ===\n",
      "      Conteggio classi: {'GET': 3}\n",
      "    Classe più quotata: GET\n",
      "\n",
      "=== Step 6: Calcolo delle probabilità normalizzate per ogni classe ===\n",
      "  Probabilità non norm: {'GET': 0.931728184223175, 'POST': 0.0, 'PUT': 0.0, 'DELETE': 0.0}\n",
      "      Probabilità norm: [1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "=== Step 7: Fallback zero-shot se la confidenza è bassa ===\n",
      "\n",
      "--- Step 8: Risultato finale ---\n",
      "       Classe predetta: GET\n",
      "           Probabilità: [1.0, 0.0, 0.0, 0.0]\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento?tipo=mutuo&ndg=123456', 'verbo_http': 'GET', 'score': np.float32(0.71034634)}\n",
      "--- ML + NLP\n",
      "                       {'endpoint': 'api/finanziamento?ndg=123456', 'verbo_http': 'DELETE', 'score': np.float32(0.64450026)}\n",
      "----------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------\n",
      "     Richiesta utente: voglio avviare un nuovo finanziamento\n",
      "       Frasi estratte: ['voglio avviare un nuovo finanziamento']\n",
      "--- NLP\n",
      "=== Step 1: Estrazione del verbo dall’input ===\n",
      "        Token estratti: [('VERBO', 'avviare')]\n",
      "        Verbo estratto: ['avviare']\n",
      "\n",
      "=== Step 2: Calcolo dell’embedding del verbo estratto ===\n",
      "        Verbo embedded: torch.Size([1, 384])\n",
      "\n",
      "=== Step 3: Calcolo della similarità coseno con gli esempi di training ===\n",
      "     Similarità coseno: tensor([0.8706, 0.7816, 0.6730, 0.6285, 0.8462, 0.6201, 0.8309, 0.7610, 0.7500,\n",
      "        0.6070, 0.5037, 0.7931, 0.8683, 0.5862, 0.6219, 0.7723, 0.7342, 0.8363,\n",
      "        0.4822, 0.4707, 0.7723, 0.7494, 0.7262, 0.7496, 0.8567, 0.7789, 0.4126,\n",
      "        0.5703, 0.8536, 0.8975, 0.3440, 0.4943, 0.8791, 0.8481, 0.3820, 0.6714,\n",
      "        0.8791, 0.7583, 0.5105, 0.4571, 0.8346, 0.7344, 0.8428, 0.3382, 0.8093,\n",
      "        0.9228, 0.5852, 0.4674, 0.8665, 0.6079, 0.5589, 0.5404, 0.9301, 0.8934,\n",
      "        0.6028, 0.5642, 0.8182, 0.8147, 0.6902, 0.3226, 0.7767, 0.7517, 0.7670,\n",
      "        0.8040, 0.6153, 0.8267, 0.3051, 0.5241, 0.7383, 0.7382, 0.6784, 0.2730,\n",
      "        0.6849, 0.6758, 0.3519, 0.5493, 0.7820, 0.7179, 0.2427, 0.5748, 0.8109,\n",
      "        0.7351, 0.5389, 0.7625, 0.6670, 0.5622, 0.5836, 0.4889, 0.5413, 0.4686,\n",
      "        0.8123, 0.5542, 0.7507, 0.6601, 0.7585, 0.4838, 0.6030, 0.6657, 0.7440,\n",
      "        0.5408, 0.6800, 0.6559, 0.8560, 0.4773, 0.7964, 0.8193, 0.7434, 0.4651,\n",
      "        0.7905, 0.8794, 0.5653, 0.5024, 0.8195, 0.8186, 0.9206, 0.7957])\n",
      "\n",
      "=== Step 4: Selezione dei top_k esempi più simili ===\n",
      "          Indici top_k: tensor([ 52,  45, 114])\n",
      "      Top_k similarità: tensor([0.9301, 0.9228, 0.9206])\n",
      "          Classi top_k: ['POST', 'POST', 'DELETE']\n",
      "\n",
      "=== Step 5: Predizione basata sulla classe più frequente ===\n",
      "      Conteggio classi: {'POST': 2, 'DELETE': 1}\n",
      "    Classe più quotata: POST\n",
      "\n",
      "=== Step 6: Calcolo delle probabilità normalizzate per ogni classe ===\n",
      "  Probabilità non norm: {'GET': 0.0, 'POST': 0.9264228343963623, 'PUT': 0.0, 'DELETE': 0.9205732345581055}\n",
      "      Probabilità norm: [0.0, 0.5015835442036344, 0.0, 0.49841645579636557]\n",
      "\n",
      "=== Step 7: Fallback zero-shot se la confidenza è bassa ===\n",
      "\n",
      "--- Step 8: Risultato finale ---\n",
      "       Classe predetta: POST\n",
      "           Probabilità: [0.0, 0.5015835442036344, 0.0, 0.49841645579636557]\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento', 'verbo_http': 'POST', 'score': np.float32(0.8377562)}\n",
      "--- ML + NLP\n",
      "                       {'endpoint': 'api/finanziamento', 'verbo_http': 'POST', 'score': np.float32(0.7539806)}\n",
      "----------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------\n",
      "     Richiesta utente: mi cerchi un finanziamento\n",
      "       Frasi estratte: ['mi cerchi un finanziamento']\n",
      "--- NLP\n",
      "=== Step 1: Estrazione del verbo dall’input ===\n",
      "        Token estratti: [('VERBO', 'cerchi')]\n",
      "        Verbo estratto: ['cerchi']\n",
      "\n",
      "=== Step 2: Calcolo dell’embedding del verbo estratto ===\n",
      "        Verbo embedded: torch.Size([1, 384])\n",
      "\n",
      "=== Step 3: Calcolo della similarità coseno con gli esempi di training ===\n",
      "     Similarità coseno: tensor([0.7992, 0.6435, 0.5364, 0.4869, 0.7073, 0.4863, 0.8084, 0.6392, 0.6010,\n",
      "        0.4801, 0.4242, 0.6443, 0.7331, 0.4838, 0.4944, 0.6978, 0.5849, 0.6979,\n",
      "        0.3674, 0.3973, 0.6978, 0.6816, 0.6405, 0.5977, 0.7277, 0.5895, 0.3618,\n",
      "        0.5217, 0.7288, 0.7018, 0.2832, 0.3603, 0.7422, 0.7147, 0.3493, 0.5103,\n",
      "        0.7675, 0.6886, 0.4748, 0.4177, 0.6993, 0.5752, 0.7147, 0.2885, 0.7085,\n",
      "        0.7876, 0.4064, 0.3104, 0.6869, 0.4886, 0.3951, 0.4280, 0.7620, 0.7471,\n",
      "        0.4836, 0.4264, 0.6600, 0.6595, 0.4858, 0.2557, 0.5900, 0.6020, 0.6441,\n",
      "        0.6424, 0.5483, 0.7217, 0.3329, 0.4175, 0.5290, 0.5189, 0.4466, 0.2085,\n",
      "        0.5320, 0.5026, 0.2680, 0.4514, 0.6320, 0.5611, 0.2445, 0.4652, 0.6822,\n",
      "        0.6087, 0.4017, 0.7141, 0.4919, 0.3639, 0.4510, 0.4043, 0.5361, 0.4715,\n",
      "        0.7207, 0.5338, 0.5374, 0.4355, 0.5333, 0.3500, 0.3874, 0.4232, 0.7174,\n",
      "        0.4873, 0.6446, 0.6130, 0.7421, 0.3772, 0.5710, 0.5971, 0.5790, 0.2898,\n",
      "        0.6854, 0.7368, 0.3885, 0.3167, 0.6204, 0.6225, 0.8190, 0.5847])\n",
      "\n",
      "=== Step 4: Selezione dei top_k esempi più simili ===\n",
      "          Indici top_k: tensor([114,   6,   0])\n",
      "      Top_k similarità: tensor([0.8190, 0.8084, 0.7992])\n",
      "          Classi top_k: ['DELETE', 'GET', 'GET']\n",
      "\n",
      "=== Step 5: Predizione basata sulla classe più frequente ===\n",
      "      Conteggio classi: {'GET': 2, 'DELETE': 1}\n",
      "    Classe più quotata: DELETE\n",
      "\n",
      "=== Step 6: Calcolo delle probabilità normalizzate per ogni classe ===\n",
      "  Probabilità non norm: {'GET': 0.8038054704666138, 'POST': 0.0, 'PUT': 0.0, 'DELETE': 0.819024920463562}\n",
      "      Probabilità norm: [0.4953108315933667, 0.0, 0.0, 0.5046891684066332]\n",
      "\n",
      "=== Step 7: Fallback zero-shot se la confidenza è bassa ===\n",
      "\n",
      "--- Step 8: Risultato finale ---\n",
      "       Classe predetta: DELETE\n",
      "           Probabilità: [0.4953108315933667, 0.0, 0.0, 0.5046891684066332]\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento?tipo=mutuo&ndg=123456', 'verbo_http': 'GET', 'score': np.float32(0.76548004)}\n",
      "--- ML + NLP\n",
      "                       {'endpoint': 'api/finanziamento?ndg=123456', 'verbo_http': 'PUT', 'score': np.float32(0.7152396)}\n",
      "----------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------\n",
      "     Richiesta utente: ho bisogno di un mutuo per la casa\n",
      "       Frasi estratte: ['ho bisogno di un mutuo per la casa']\n",
      "--- NLP\n",
      "=== Step 1: Estrazione del verbo dall’input ===\n",
      "        Token estratti: [('VERBO', 'ho')]\n",
      "        Verbo estratto: ['ho']\n",
      "\n",
      "=== Step 2: Calcolo dell’embedding del verbo estratto ===\n",
      "        Verbo embedded: torch.Size([1, 384])\n",
      "\n",
      "=== Step 3: Calcolo della similarità coseno con gli esempi di training ===\n",
      "     Similarità coseno: tensor([0.6905, 0.7039, 0.5185, 0.4612, 0.7459, 0.6404, 0.6281, 0.5839, 0.6707,\n",
      "        0.5896, 0.3650, 0.6196, 0.7005, 0.5936, 0.6299, 0.6607, 0.5640, 0.7510,\n",
      "        0.3294, 0.3263, 0.6607, 0.6191, 0.5537, 0.5949, 0.8094, 0.6981, 0.2928,\n",
      "        0.5338, 0.7272, 0.6585, 0.2153, 0.3267, 0.6572, 0.6223, 0.2757, 0.4440,\n",
      "        0.7325, 0.6518, 0.3884, 0.3682, 0.6917, 0.6751, 0.7092, 0.1929, 0.6895,\n",
      "        0.7271, 0.5128, 0.3936, 0.7039, 0.4489, 0.3609, 0.3561, 0.7472, 0.6698,\n",
      "        0.4658, 0.4175, 0.6575, 0.6459, 0.4921, 0.1722, 0.6489, 0.5344, 0.6111,\n",
      "        0.6702, 0.4282, 0.6110, 0.1896, 0.3829, 0.5699, 0.6108, 0.5165, 0.1567,\n",
      "        0.5264, 0.6106, 0.2285, 0.4592, 0.5780, 0.6073, 0.1488, 0.3484, 0.7164,\n",
      "        0.6812, 0.3274, 0.6146, 0.5237, 0.5023, 0.4638, 0.3926, 0.3376, 0.2665,\n",
      "        0.7141, 0.3974, 0.5556, 0.5590, 0.6045, 0.4236, 0.4098, 0.5112, 0.6616,\n",
      "        0.3699, 0.4949, 0.4610, 0.7020, 0.3572, 0.5439, 0.5312, 0.5897, 0.3931,\n",
      "        0.6031, 0.7088, 0.3445, 0.2646, 0.6137, 0.6095, 0.7800, 0.5608])\n",
      "\n",
      "=== Step 4: Selezione dei top_k esempi più simili ===\n",
      "          Indici top_k: tensor([ 24, 114,  17])\n",
      "      Top_k similarità: tensor([0.8094, 0.7800, 0.7510])\n",
      "          Classi top_k: ['GET', 'DELETE', 'GET']\n",
      "\n",
      "=== Step 5: Predizione basata sulla classe più frequente ===\n",
      "      Conteggio classi: {'GET': 2, 'DELETE': 1}\n",
      "    Classe più quotata: GET\n",
      "\n",
      "=== Step 6: Calcolo delle probabilità normalizzate per ogni classe ===\n",
      "  Probabilità non norm: {'GET': 0.7801903486251831, 'POST': 0.0, 'PUT': 0.0, 'DELETE': 0.779962420463562}\n",
      "      Probabilità norm: [0.5000730467445679, 0.0, 0.0, 0.49992695325543207]\n",
      "\n",
      "=== Step 7: Fallback zero-shot se la confidenza è bassa ===\n",
      "\n",
      "--- Step 8: Risultato finale ---\n",
      "       Classe predetta: GET\n",
      "           Probabilità: [0.5000730467445679, 0.0, 0.0, 0.49992695325543207]\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento?ndg=123456', 'verbo_http': 'PUT', 'score': np.float32(0.37362602)}\n",
      "--- ML + NLP\n",
      "                       La richiesta non trova corrispondenza con nessuna API. (score: 0.3862561)\n",
      "----------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------\n",
      "     Richiesta utente: vado a comprarmi una pizza\n",
      "       Frasi estratte: ['vado a comprarmi una pizza']\n",
      "--- NLP\n",
      "=== Step 1: Estrazione del verbo dall’input ===\n",
      "        Token estratti: [('VERBO', 'vado'), ('VERBO', 'comprarmi')]\n",
      "        Verbo estratto: ['vado', 'comprarmi']\n",
      "\n",
      "=== Step 2: Calcolo dell’embedding del verbo estratto ===\n",
      "        Verbo embedded: torch.Size([2, 384])\n",
      "\n",
      "=== Step 3: Calcolo della similarità coseno con gli esempi di training ===\n",
      "     Similarità coseno: tensor([0.7375, 0.7924, 0.6130, 0.5185, 0.7958, 0.7714, 0.7190, 0.6031, 0.8275,\n",
      "        0.7746, 0.4251, 0.6470, 0.7283, 0.6744, 0.7638, 0.7059, 0.6132, 0.8182,\n",
      "        0.3863, 0.3695, 0.7059, 0.6759, 0.5992, 0.5930, 0.8013, 0.8205, 0.3247,\n",
      "        0.6238, 0.8071, 0.6888, 0.2458, 0.4100, 0.7150, 0.6944, 0.3421, 0.4901,\n",
      "        0.7952, 0.6865, 0.4462, 0.4088, 0.8309, 0.8512, 0.8328, 0.2207, 0.7502,\n",
      "        0.7840, 0.6367, 0.4576, 0.7651, 0.4654, 0.4616, 0.4644, 0.7898, 0.7392,\n",
      "        0.5629, 0.5115, 0.7184, 0.6935, 0.5811, 0.1488, 0.6868, 0.5953, 0.7148,\n",
      "        0.7904, 0.4456, 0.6345, 0.2279, 0.4997, 0.6490, 0.7237, 0.6181, 0.1764,\n",
      "        0.5972, 0.7417, 0.2523, 0.5211, 0.6425, 0.7282, 0.1151, 0.4131, 0.8315,\n",
      "        0.8321, 0.3891, 0.6903, 0.6671, 0.6731, 0.5608, 0.4049, 0.3934, 0.3335,\n",
      "        0.8294, 0.4816, 0.6411, 0.6999, 0.7335, 0.5717, 0.4618, 0.6237, 0.7498,\n",
      "        0.3930, 0.5746, 0.5481, 0.7171, 0.4444, 0.6260, 0.6155, 0.6475, 0.3991,\n",
      "        0.6561, 0.8007, 0.3874, 0.3033, 0.6646, 0.6875, 0.8233, 0.6070])\n",
      "\n",
      "=== Step 4: Selezione dei top_k esempi più simili ===\n",
      "          Indici top_k: tensor([41, 42, 81])\n",
      "      Top_k similarità: tensor([0.8512, 0.8328, 0.8321])\n",
      "          Classi top_k: ['POST', 'POST', 'PUT']\n",
      "\n",
      "=== Step 5: Predizione basata sulla classe più frequente ===\n",
      "      Conteggio classi: {'POST': 2, 'PUT': 1}\n",
      "    Classe più quotata: POST\n",
      "\n",
      "=== Step 6: Calcolo delle probabilità normalizzate per ogni classe ===\n",
      "  Probabilità non norm: {'GET': 0.0, 'POST': 0.8420004844665527, 'PUT': 0.8320997953414917, 'DELETE': 0.0}\n",
      "      Probabilità norm: [0.0, 0.5029570179410627, 0.49704298205893727, 0.0]\n",
      "\n",
      "=== Step 7: Fallback zero-shot se la confidenza è bassa ===\n",
      "\n",
      "--- Step 8: Risultato finale ---\n",
      "       Classe predetta: POST\n",
      "           Probabilità: [0.0, 0.5029570179410627, 0.49704298205893727, 0.0]\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento?tipo=mutuo&ndg=123456', 'verbo_http': 'GET', 'score': np.float32(0.12222385)}\n",
      "--- ML + NLP\n",
      "                       La richiesta non trova corrispondenza con nessuna API. (score: 0.16029716)\n",
      "----------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------\n",
      "     Richiesta utente: mi crei un finanziamento con ndg 123456 e tipo mutuo\n",
      "       Frasi estratte: ['mi crei un finanziamento con ndg 123456 e tipo mutuo']\n",
      "--- NLP\n",
      "=== Step 1: Estrazione del verbo dall’input ===\n",
      "        Token estratti: [('VERBO', 'crei')]\n",
      "        Verbo estratto: ['crei']\n",
      "\n",
      "=== Step 2: Calcolo dell’embedding del verbo estratto ===\n",
      "        Verbo embedded: torch.Size([1, 384])\n",
      "\n",
      "=== Step 3: Calcolo della similarità coseno con gli esempi di training ===\n",
      "     Similarità coseno: tensor([0.5492, 0.6168, 0.6063, 0.4602, 0.6129, 0.5878, 0.5334, 0.4570, 0.6564,\n",
      "        0.5716, 0.3710, 0.5226, 0.5784, 0.5494, 0.6934, 0.6013, 0.4717, 0.6708,\n",
      "        0.3273, 0.3193, 0.6013, 0.5422, 0.4570, 0.3926, 0.5906, 0.6085, 0.3896,\n",
      "        0.5956, 0.6200, 0.5014, 0.1641, 0.3076, 0.5167, 0.5125, 0.3526, 0.3263,\n",
      "        0.6534, 0.5201, 0.3489, 0.2965, 0.6253, 0.6301, 0.6342, 0.1478, 0.5765,\n",
      "        0.5865, 0.5519, 0.3782, 0.5770, 0.3370, 0.2918, 0.3017, 0.5875, 0.5530,\n",
      "        0.3979, 0.3431, 0.5448, 0.5108, 0.3951, 0.0934, 0.5304, 0.4313, 0.5612,\n",
      "        0.6210, 0.2908, 0.4543, 0.1867, 0.3331, 0.4479, 0.5100, 0.4762, 0.1165,\n",
      "        0.3986, 0.5066, 0.2061, 0.4719, 0.4731, 0.5600, 0.1161, 0.2595, 0.6596,\n",
      "        0.6840, 0.3104, 0.4983, 0.4460, 0.4367, 0.4629, 0.2645, 0.2734, 0.2410,\n",
      "        0.6578, 0.3078, 0.4092, 0.4353, 0.5851, 0.4511, 0.2771, 0.3842, 0.5128,\n",
      "        0.3659, 0.4650, 0.4422, 0.5207, 0.3790, 0.4224, 0.4092, 0.4718, 0.2767,\n",
      "        0.4740, 0.6036, 0.2163, 0.1503, 0.4923, 0.4857, 0.6278, 0.4017])\n",
      "\n",
      "=== Step 4: Selezione dei top_k esempi più simili ===\n",
      "          Indici top_k: tensor([14, 81, 17])\n",
      "      Top_k similarità: tensor([0.6934, 0.6840, 0.6708])\n",
      "          Classi top_k: ['GET', 'PUT', 'GET']\n",
      "\n",
      "=== Step 5: Predizione basata sulla classe più frequente ===\n",
      "      Conteggio classi: {'GET': 2, 'PUT': 1}\n",
      "    Classe più quotata: GET\n",
      "\n",
      "=== Step 6: Calcolo delle probabilità normalizzate per ogni classe ===\n",
      "  Probabilità non norm: {'GET': 0.6821118593215942, 'POST': 0.0, 'PUT': 0.6839824914932251, 'DELETE': 0.0}\n",
      "      Probabilità norm: [0.49931533566092445, 0.0, 0.5006846643390755, 0.0]\n",
      "\n",
      "=== Step 7: Fallback zero-shot se la confidenza è bassa ===\n",
      "\n",
      "--- Step 8: Risultato finale ---\n",
      "       Classe predetta: GET\n",
      "           Probabilità: [0.49931533566092445, 0.0, 0.5006846643390755, 0.0]\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento', 'verbo_http': 'POST', 'score': np.float32(0.6849687)}\n",
      "--- ML + NLP\n",
      "                       {'endpoint': 'api/finanziamento', 'verbo_http': 'POST', 'score': np.float32(0.66654027)}\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "esempi_richiesta = [\n",
    "    \"cercami i finanziamenti dell'ndg 123456\",\n",
    "    \"voglio avviare un nuovo finanziamento\",\n",
    "    \"mi cerchi un finanziamento\",\n",
    "    \"ho bisogno di un mutuo per la casa\",\n",
    "    \"vado a comprarmi una pizza\",\n",
    "    \"mi crei un finanziamento con ndg 123456 e tipo mutuo\",\n",
    "]\n",
    "\n",
    "for richiesta in esempi_richiesta:\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(get_api_2(richiesta, include_oggetto=False, ml_weight=0.1, nlp_weight=0.9, soglia_similarita=0.6)),\n",
    "    print(\"----------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bdceee",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- Pensare a come gestire l'inserimento di più frasi da parte dell'utente in un'unica richiesta\n",
    "- Migliorare la parte di ML, ad esempio: \n",
    "  - cercare una libreria che data una parola ti fornisce tutti i sinonimi possibili (o una cosa del genere), potrebbe essere utile per costruire un dataset di input in modo automatico\n",
    "  - ci sono modelli migliore del LogisticRegression? \n",
    "  - trovare una parametrizzazione efficiente per addestrare il modello scelto\n",
    "- Capire come migliorare \"live\" l'algoritmo... renforce learning?\n",
    "- AI può suuggerire le prossime azioni da fare (dettate dal workflow)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
