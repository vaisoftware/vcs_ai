{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ea8a0f",
   "metadata": {},
   "source": [
    "# Primo caso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab74370",
   "metadata": {},
   "source": [
    "- pip install scikit-learn\n",
    "- pip install sentence-transformers\n",
    "- pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7920a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libreria che consente la rappresentazione vettoriale (embedded) di frasi anziché parole\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Libreria per calcolare la similarità coseno tra vettori (la similiarità coseno misura quanto due vettori sono simili)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Libreria per il rilevamento della lingua del testo\n",
    "from langdetect import detect\n",
    "\n",
    "# Carica modello multilingua potente che comprende l'italiano\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Lista statica di API con descrizioni ed endpoint\n",
    "api_catalog = [\n",
    "    {\n",
    "        \"descrizione\": \"Creazione nuovo finanziamento. Creazione per tipo e ndg\",\n",
    "        \"endpoint\": \"api/finanziamento\",\n",
    "        \"verbo\": \"POST\",\n",
    "    },\n",
    "    {\n",
    "        \"descrizione\": \"Ricerca un finanziamento esistente. Ricerca per tipo e ndg\",\n",
    "        \"endpoint\": \"api/finanziamento&tipo=mutuo&ndg=123456\",\n",
    "        \"verbo\": \"GET\",\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_api(testo_input, soglia_similarita=0.5):\n",
    "    try:\n",
    "        # Verifica che la lingua sia italiana\n",
    "        if detect(testo_input) != \"it\":\n",
    "            return \"Per favore fornisci il testo in italiano.\"\n",
    "\n",
    "        # Calcola embedding del testo utente\n",
    "        embedding_input = model.encode([testo_input])\n",
    "\n",
    "        migliori_match = {\"endpoint\": None, \"score\": 0.0}\n",
    "\n",
    "        # Confronta con le descrizioni delle API\n",
    "        for api in api_catalog:\n",
    "            # Calcola embedding della descrizione dell'API\n",
    "            embedding_descrizione = model.encode([api[\"descrizione\"]])\n",
    "            # Calcola la similarità coseno tra l'input e la descrizione dell'API\n",
    "            sim = cosine_similarity(embedding_input, embedding_descrizione)[0][0]\n",
    "\n",
    "            # Aggiorna il miglior match se la similarità è maggiore della soglia\n",
    "            if sim > migliori_match[\"score\"]:\n",
    "                migliori_match = {\"endpoint\": api[\"endpoint\"], \"score\": sim}\n",
    "\n",
    "        # Controlla se il miglior match supera la soglia di similarità\n",
    "        if migliori_match[\"score\"] >= soglia_similarita:\n",
    "            return f\"{migliori_match['endpoint']}\"\n",
    "        else:\n",
    "            return \"La richiesta non trova corrispondenza con nessuna API. Riprova.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Errore durante l'elaborazione: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fdb0f9",
   "metadata": {},
   "source": [
    "# Test primo caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf43d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "esempi_richiesta = [\n",
    "    \"cercami i finanziamenti dell'ndg 123456\",\n",
    "    \"voglio avviare un nuovo finanziamento\",\n",
    "    \"mi cerchi un finanziamento\",\n",
    "    \"ho bisogno di un mutuo per la casa\",\n",
    "    \"vado a comprarmi una pizza\",\n",
    "    \"mi crei un finanziamento con ndg 123456 e tipo mutuo\",\n",
    "]\n",
    "\n",
    "for richiesta in esempi_richiesta:\n",
    "    print(f\"  Richiesta utente: {richiesta}\")\n",
    "    print(f\"Endpoint associato: {get_api(richiesta)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0628d17c",
   "metadata": {},
   "source": [
    "# Secondo caso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f50adb",
   "metadata": {},
   "source": [
    "- pip install spacy\n",
    "- python -m spacy download it_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915649c0",
   "metadata": {},
   "source": [
    "# Importo librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02975895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libreria per l'elaborazione del linguaggio naturale\n",
    "import spacy\n",
    "# Libreria per operazioni numeriche e matriciali\n",
    "import numpy as np\n",
    "# Libreria per il modello di classificazione\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Libreria che consente la rappresentazione vettoriale (embedded) di frasi anziché parole\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "# Libreria per calcolare la similarità coseno tra vettori (la similiarità coseno misura quanto due vettori sono simili)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Libreria per modelli di trasformatori (transformers)\n",
    "from transformers import pipeline \n",
    "# Disabilita i warning di transformers\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "# Libreria per gestire tensori e modelli di deep learning\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8802331",
   "metadata": {},
   "source": [
    "# Addestramento machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48469fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [\n",
    "    # ==== GET ====\n",
    "    \"cerca\", \"cercami\", \"fai una ricerca\", \"esegui una ricerca\",\n",
    "    \"trova\", \"trovami\", \"rintraccia\", \"identifica\",\n",
    "    \"recupera\", \"recuperami\", \"ottieni dati\", \"estrai informazioni\",\n",
    "    \"mostra\", \"mostrami\", \"fammi vedere\", \"visualizza\",\n",
    "    \"leggi\", \"leggimi\", \"accedi ai dati\", \"ottieni i dati\",\n",
    "    \"visualizza\", \"visualizzami\", \"rendi visibile\", \"presenta\",\n",
    "    \"vedi\", \"vedimi\", \"guarda i dati\", \"dammi una vista\",\n",
    "    \"estrai\", \"estraimi\", \"scarica dati\", \"porta fuori dati\",\n",
    "    \"accedi\", \"accedimi\", \"entra nei dati\", \"consulta\",\n",
    "\n",
    "    # ==== POST ====\n",
    "    \"crea\", \"creami\", \"genera nuovo\", \"costruisci un nuovo\",\n",
    "    \"inserisci\", \"inseriscimi\", \"aggiungi\", \"carica nuovi dati\",\n",
    "    \"richiedi\", \"richiedimi\", \"fai una richiesta\", \"manda una richiesta\",\n",
    "    \"apri\", \"aprimi\", \"avvia una nuova pratica\", \"inizia procedura\",\n",
    "    \"avvia\", \"avviami\", \"dai inizio\", \"comincia processo\",\n",
    "    \"registra\", \"registrami\", \"salva nuovo\", \"archivia dati\",\n",
    "    \"attiva\", \"attivami\", \"metti in funzione\", \"abilita\",\n",
    "    \"compila\", \"compilami\", \"riempi i dati\", \"completa il modulo\",\n",
    "\n",
    "    # ==== PUT ====\n",
    "    \"aggiorna\", \"aggiornami\", \"fai un aggiornamento\", \"modifica con nuovi dati\",\n",
    "    \"modifica\", \"modificami\", \"cambia i dati\", \"rivedi i valori\",\n",
    "    \"correggi\", \"correggimi\", \"sistema dati\", \"risolvi errori\",\n",
    "    \"rivedi\", \"rivedimi\", \"verifica e modifica\", \"ritocca\",\n",
    "    \"sostituisci\", \"sostituiscimi\", \"cambia con altro\", \"scambia contenuto\",\n",
    "    \"ricalcola\", \"ricalcolami\", \"rifai i conti\", \"esegui nuovo calcolo\",\n",
    "\n",
    "    # ==== DELETE ====\n",
    "    \"elimina\", \"eliminami\", \"cancella definitivamente\", \"rimuovi per sempre\",\n",
    "    \"cancella\", \"cancellami\", \"butta via\", \"togli dai dati\",\n",
    "    \"rimuovi\", \"rimuovimi\", \"escludi\", \"levami dai dati\",\n",
    "    \"revoca\", \"revocami\", \"invalida\", \"annulla autorizzazione\",\n",
    "    \"annulla\", \"annullami\", \"ferma l’operazione\", \"interrompi processo\",\n",
    "    \"disattiva\", \"disattivami\", \"spegni\", \"rendi inattivo\"\n",
    "]\n",
    "\n",
    "y_train = [\n",
    "    # ==== GET ====\n",
    "    *[\"GET\"]*36,\n",
    "    # ==== POST ====\n",
    "    *[\"POST\"]*32,\n",
    "    # ==== PUT ====\n",
    "    *[\"PUT\"]*24,\n",
    "    # ==== DELETE ====\n",
    "    *[\"DELETE\"]*24\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900bc43",
   "metadata": {},
   "source": [
    "Opzione 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "645fbabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il modello italiano\n",
    "nlp = spacy.load(\"it_core_news_md\")\n",
    "\n",
    "#metodo per trasformare x_train che contiene frasi in vettori numerici\n",
    "def vectorizza(frasi):\n",
    "    return np.array([nlp(frase).vector for frase in frasi])\n",
    "\n",
    "# Vettorizza il training set\n",
    "X_vect = vectorizza(X_train)\n",
    "\n",
    "# Definisci il classificatore\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Allena il classificatore\n",
    "clf.fit(X_vect, y_train)\n",
    "\n",
    "# Metodo per estrarre verbo e complemento oggetto da una frase\n",
    "def estrai_verbo_oggetto(frase: str, include_oggetto: bool = False):\n",
    "    # Analizza la frase con spaCy\n",
    "    doc = nlp(frase)\n",
    "    risultati = []\n",
    "    # Itera sui token della frase\n",
    "    for token in doc:\n",
    "        # Verbi\n",
    "        if token.pos_ == \"VERB\":\n",
    "            # Aggiungi il verbo alla lista dei risultati\n",
    "            risultati.append((\"VERBO\", token.text))\n",
    "        # Complemento oggetto (solo se richiesto dal flag)\n",
    "        if include_oggetto and token.dep_ == \"obj\":\n",
    "            # Aggiungi l'oggetto alla lista dei risultati\n",
    "            risultati.append((\"OGGETTO\", token.text))\n",
    "    return risultati\n",
    "\n",
    "def classifica_http(testo_input: str, include_oggetto: bool = False):\n",
    "    # Estraggo le caratteristiche del verbo (e oggetto se richiesto)\n",
    "    caratteristiche_verbo = estrai_verbo_oggetto(testo_input, include_oggetto)\n",
    "    if include_oggetto:\n",
    "        # Estraggo sia la parola del verbo che dell'oggetto (escludendo etichetta e posizioni)\n",
    "        verbo = [v[1] for v in caratteristiche_verbo if v[0] == \"VERBO\" or v[0] == \"OGGETTO\"]\n",
    "    else:\n",
    "        # Estraggo solo la parola del verbo (escludendo etichetta e posizioni)\n",
    "        verbo = [v[1] for v in caratteristiche_verbo if v[0] == \"VERBO\"]\n",
    "    # Vettorizzazione\n",
    "    verbo_vect = vectorizza(verbo)\n",
    "    # Predizione\n",
    "    verbo_predetto = clf.predict(verbo_vect)[0]\n",
    "    # Probabilità per tutte le classi\n",
    "    probs = clf.predict_proba(verbo_vect)[0]   # array 1D tipo [0.05, 0.10, 0.82, 0.03]\n",
    "    # Indice della classe predetta\n",
    "    verbo_predetto_indice = clf.classes_.tolist().index(verbo_predetto)\n",
    "    # Probabilità della classe predetta\n",
    "    score_verbo_predetto = probs[verbo_predetto_indice]\n",
    "    print(\"--- ML\")\n",
    "    print(f\"       Verbo estratto: {verbo}\")\n",
    "    print(f\"  Verbo http predetto: {verbo_predetto}\")\n",
    "    print(f\"               Classi: {clf.classes_}\")\n",
    "    print(f\"          Probabilità: {probs}\")\n",
    "    print(f\"  Indice della classe: {verbo_predetto_indice}\")\n",
    "    print(f\"Probabilità del verbo: {score_verbo_predetto}\")\n",
    "    #esempio\n",
    "    #   Verbo http predetto       → 'POST'\n",
    "    #   Classi                    → ['DELETE', 'GET', 'POST', 'PUT']\n",
    "    #   Probabilità               → [0.05, 0.10, 0.82, 0.03]  # stesso ordine\n",
    "    #   Indice della classe       → 2  (perché 'POST' è il 3° elemento)\n",
    "    #   Probabilità del verbo     → verbo_probabilita[2] = 0.82\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e3ea94",
   "metadata": {},
   "source": [
    "Opzione 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e8c37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modello di embedding\n",
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Calcolo gli embeddings dei tuoi esempi di training\n",
    "X_emb = embedding_model.encode(X_train, convert_to_tensor=True)\n",
    "\"\"\" \n",
    "# print(X_emb)\n",
    "tensor([[ 0.012,  0.034, ..., -0.021],\n",
    "        [ 0.020,  0.040, ..., -0.010],\n",
    "        [ 0.015,  0.028, ..., -0.018],\n",
    "        ...,\n",
    "        [-0.012, 0.033, ..., 0.019]])\n",
    "# print(\"Shape:\", X_emb.shape)\n",
    "Shape: torch.Size([116, 384]) \n",
    "\"\"\"\n",
    "\n",
    "# Zero-shot fallback: \n",
    "# - zero-shot significa che si usa un modello pre-addestrato, che non necessita di addestramento sui tuoi esempi, per classificare i miei esempi\n",
    "# - fallback perché uso prima un metodo principale e se la confidenza è bassa uso questo\n",
    "# In poche parole, serve solo se vuoi gestire verbi/frasi molto fuori dai tuoi esempi\n",
    "\n",
    "# Uso il modello BART di Facebook addestrato su MNLI (Multi-Genre Natural Language Inference)\n",
    "# MNLI è un dataset di inferenza testuale, dove il modello impara a capire se una frase implica, contraddice o è neutrale rispetto a un'altra frase\n",
    "zero_shot_model = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\"\n",
    ")\n",
    "\n",
    "# Etichette HTTP\n",
    "http_labels = [\"GET\", \"POST\", \"PUT\", \"DELETE\"]\n",
    "\n",
    "def classifica_http_2(testo_input: str, include_oggetto: bool = False, top_k: int = 3, fallback_soglia: float = 0.65):\n",
    "    print(\"--- NLP\")\n",
    "    \"\"\" \n",
    "    ESEMPIO\n",
    "    \"butta via i documenti\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # print(\"=== Step 1: Estrazione del verbo dall’input ===\")\n",
    "    caratteristiche_verbo = estrai_verbo_oggetto(testo_input, include_oggetto)\n",
    "    # print(\"       Token estratti:\", caratteristiche_verbo)\n",
    "    if include_oggetto:\n",
    "        # Estraggo sia la parola del verbo che dell'oggetto (escludendo etichetta e posizioni)\n",
    "        verbo = [v[1] for v in caratteristiche_verbo if v[0] == \"VERBO\" or v[0] == \"OGGETTO\"]\n",
    "    else:\n",
    "        # Estraggo solo la parola del verbo (escludendo etichetta e posizioni)\n",
    "        verbo = [v[1] for v in caratteristiche_verbo if v[0] == \"VERBO\"]\n",
    "    # print(\"       Verbo estratto:\", verbo)\n",
    "    \"\"\" \n",
    "    Token estratti: [('VERBO','butta')]\n",
    "    Verbo estratto: ['butta'] \n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"\\n=== Step 2: Calcolo dell’embedding del verbo estratto ===\")\n",
    "    verbo_emb = embedding_model.encode(verbo, convert_to_tensor=True)\n",
    "    # print(\"       Verbo embedded:\", verbo_emb.shape)\n",
    "    \"\"\" \n",
    "    Verbo embedded: (1, 384)\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"\\n=== Step 3: Calcolo della similarità coseno con gli esempi di training ===\")\n",
    "    cos_scores = util.cos_sim(verbo_emb, X_emb)[0] \n",
    "    # print(\"    Similarità coseno:\", cos_scores)\n",
    "    \"\"\" \n",
    "    Similarità coseno: [0.45, 0.12, 0.08, 0.78, ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"\\n=== Step 4: Selezione dei top_k esempi più simili ===\")\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "    preds = [y_train[i] for i in top_results] \n",
    "    verbo_predetto = preds[0] \n",
    "    confidenza = float(cos_scores[top_results[0]])\n",
    "    # print(\"         Indici top_k:\", top_results)\n",
    "    # print(\"     Top_k similarità:\", cos_scores[top_results])\n",
    "    # print(\"         Classi top_k:\", preds)\n",
    "    \"\"\" \n",
    "    Indici top_k: [3, 6, 0]\n",
    "    Valori top_k similarità: [0.78, 0.65, 0.45]\n",
    "    Classi top_k: ['DELETE', 'GET', 'GET']\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"\\n=== Step 5: Predizione basata sulla classe più frequente ===\")\n",
    "    # conta quante volte compare ogni classe nei top_k\n",
    "    counts = {label: preds.count(label) for label in set(preds)} \n",
    "    # perché prendere la classe con il conteggio massimo?\n",
    "    # vantaggio:\n",
    "    # - robustezza contro outlier: se uno dei top_k è un outlier\n",
    "    # svantaggio:\n",
    "    # - non considera la similarità: potrei avere 2 esempi \"GET\" con similarità 0.45 e 0.44, e 1 esempio \"DELETE\" con similarità 0.78\n",
    "    verbo_predetto_2 = max(counts, key=counts.get)\n",
    "    # print(\"     Conteggio classi:\", counts)\n",
    "    # print(\"   Classe più quotata:\", verbo_predetto)\n",
    "    \"\"\" \n",
    "    Conteggio classi: {'DELETE': 1, 'GET': 2}\n",
    "    Classe più quotata: GET\n",
    "    # print(\"Similarità max:\", confidenza)\n",
    "    Confidenza (similarità max): 0.78\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"\\n=== Step 6: Calcolo delle probabilità normalizzate per ogni classe ===\")\n",
    "    probs_dict = {}\n",
    "    for label in http_labels:\n",
    "        # prendo tutti i top_results che hanno questa label\n",
    "        label_indices = [i for i in top_results if y_train[i] == label]\n",
    "        if label_indices:\n",
    "            # converto cos_scores in numpy solo se è un tensor\n",
    "            cos_scores_np = cos_scores.cpu().detach().numpy() if isinstance(cos_scores, torch.Tensor) else cos_scores\n",
    "            # media delle similarità per questa classe\n",
    "            probs_dict[label] = float(np.mean(cos_scores_np[label_indices]))\n",
    "        else:\n",
    "            probs_dict[label] = 0.0\n",
    "    # print(\" Probabilità non norm:\", probs_dict)\n",
    "    # Normalizzo in modo che la somma sia 1\n",
    "    total = sum(probs_dict.values())\n",
    "    if total > 0:\n",
    "        probs = [probs_dict[label]/total for label in http_labels]\n",
    "    else:\n",
    "        # fallback uniforme se total = 0\n",
    "        probs = [1/len(http_labels)]*len(http_labels)\n",
    "    # print(\"     Probabilità norm:\", probs)\n",
    "    \"\"\" \n",
    "    Probabilità non normalizzate: {'GET': 0.285, 'POST': 0.0, 'PUT': 0.0, 'DELETE': 0.78}\n",
    "    Probabilità normalizzate: [0.27, 0.0, 0.0, 0.73]\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"\\n=== Step 7: Fallback zero-shot se la confidenza è bassa ===\")\n",
    "    if confidenza < fallback_soglia:\n",
    "        zero_shot_res = zero_shot_model(testo_input, candidate_labels=http_labels)\n",
    "        verbo_predetto_zero_shot = zero_shot_res['labels'][0]\n",
    "        probs_zero_shot = [zero_shot_res['scores'][zero_shot_res['labels'].index(label)] for label in http_labels]\n",
    "        # print(\"       Caso zero shot\")\n",
    "        # print(\"               Classi:\", zero_shot_res['labels'])\n",
    "        # print(\"          Probabilità:\", zero_shot_res['scores'])\n",
    "        # print(\"        Classe finale:\", verbo_predetto_zero_shot)\n",
    "        if zero_shot_res['scores'][0] > confidenza:\n",
    "            print(\"       Caso zero shot\")\n",
    "            verbo_predetto = verbo_predetto_zero_shot\n",
    "            probs = probs_zero_shot\n",
    "\n",
    "\n",
    "    # print(\"\\n--- Step 8: Risultato finale ---\")\n",
    "    print(\"               Classi:\", http_labels)\n",
    "    print(\"          Probabilità:\", probs)\n",
    "    print(\"      Classe predetta:\", verbo_predetto)\n",
    "    \"\"\" \n",
    "    Classe predetta: GET\n",
    "    Probabilità di tutte le classi: [0.27, 0.0, 0.0, 0.73]\n",
    "    \"\"\"\n",
    "\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e154ba",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b112c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodo per analizzare il testo e suddividerlo in frasi\n",
    "\"\"\" Il metodo riconosce più frasi separate da punteggiatura, invece, ad esempio, non riconosce invece frasi congiunte da \"e\" o \"poi\" \"\"\"\n",
    "def analizza_frasi(testo: str):\n",
    "    # Analizza la frase con spaCy\n",
    "    doc = nlp(testo)\n",
    "    # Estrai le frasi dal testo\n",
    "    frasi = [sent.text.strip() for sent in doc.sents] \n",
    "    print(f\"       Frasi estratte: {frasi}\")\n",
    "    return len(frasi), frasi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0687a6",
   "metadata": {},
   "source": [
    "# Api da individuare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "281f1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista statica di API con descrizioni ed endpoint\n",
    "api_catalog = [\n",
    "    {\n",
    "        \"descrizione\": \"Creazione nuovo finanziamento. Creazione per tipo e ndg\",\n",
    "        \"endpoint\": \"api/finanziamento\",\n",
    "        \"verbo_http\": \"POST\"\n",
    "    },\n",
    "    {\n",
    "        \"descrizione\": \"Ricerca un finanziamento esistente. Ricerca per tipo e ndg\",\n",
    "        \"endpoint\": \"api/finanziamento?tipo=mutuo&ndg=123456\",\n",
    "        \"verbo_http\": \"GET\"\n",
    "    },\n",
    "    {\n",
    "        \"descrizione\": \"Cancellazione finanziamento esistente. Cancellazione per ndg\",\n",
    "        \"endpoint\": \"api/finanziamento?ndg=123456\",\n",
    "        \"verbo_http\": \"DELETE\"\n",
    "    },\n",
    "    {\n",
    "        \"descrizione\": \"Aggiornamento finanziamento esistente. Aggiornamento per ndg\",\n",
    "        \"endpoint\": \"api/finanziamento?ndg=123456\",\n",
    "        \"verbo_http\": \"PUT\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f620f",
   "metadata": {},
   "source": [
    "# Algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "518d980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica modello multilingua potente che comprende l'italiano\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def get_api_2(testo_input, tipo_classificatore=\"ML\", include_oggetto=False, ml_weight=0.5, nlp_weight=0.5, soglia_similarita=0.5):\n",
    "    try:\n",
    "        print(f\"     Richiesta utente: {testo_input}\")\n",
    "\n",
    "        # Verifica che la richiesta contenga una sola frase\n",
    "        num_frasi, lista_frasi = analizza_frasi(testo_input)\n",
    "        if num_frasi > 1:\n",
    "            return f\"                       La richiesta contiene {num_frasi} frasi. Per favore invia una sola frase alla volta. Frasi rilevate: {lista_frasi}\"\n",
    "        \n",
    "        # Recupera le probabilità per ogni verbo HTTP\n",
    "        if tipo_classificatore == \"ML\":\n",
    "            probs = classifica_http(testo_input, include_oggetto)\n",
    "        else:\n",
    "            probs = classifica_http_2(testo_input, include_oggetto)\n",
    "\n",
    "        # Calcola embedding del testo utente\n",
    "        embedding_input = model.encode([testo_input])\n",
    "\n",
    "        migliore_match = {\"endpoint\": None, \"verbo_http\": None, \"score\": 0.0}\n",
    "        migliore_match_composito = {\"endpoint\": None, \"verbo_http\": None, \"score\": 0.0}\n",
    "\n",
    "        # Confronta con le descrizioni delle API\n",
    "        for api in api_catalog:\n",
    "\n",
    "            # Calcola embedding della descrizione dell'API\n",
    "            embedding_api = model.encode([api[\"descrizione\"]])\n",
    "\n",
    "            # Calcola la similarità coseno tra l'input e la descrizione dell'API\n",
    "            sim = cosine_similarity(embedding_input, embedding_api)[0][0]\n",
    "\n",
    "            # Aggiorna il miglior match se la similarità è maggiore della soglia\n",
    "            if sim > migliore_match[\"score\"]:\n",
    "                migliore_match = {\"endpoint\": api[\"endpoint\"], \"verbo_http\": api[\"verbo_http\"], \"score\": sim}\n",
    "\n",
    "            # Combina i due score (similarità e probabilità verbo) con pesi alpha e beta\n",
    "            if tipo_classificatore == \"ML\":\n",
    "                verbo_indice = clf.classes_.tolist().index(api[\"verbo_http\"])\n",
    "            else:\n",
    "                verbo_indice = http_labels.index(api[\"verbo_http\"])\n",
    "            score_verbo = probs[verbo_indice]\n",
    "            sim_composito = ml_weight * score_verbo + nlp_weight * sim\n",
    "            if sim_composito > migliore_match_composito[\"score\"]:\n",
    "                migliore_match_composito = {\"endpoint\": api[\"endpoint\"], \"verbo_http\": api[\"verbo_http\"], \"score\": sim_composito}\n",
    "            \n",
    "\n",
    "        print(\"--- NLP 2\")\n",
    "        print(f\"    Similarità coseno: {migliore_match}\")\n",
    "        print(f\"--- {tipo_classificatore} + NLP 2\")\n",
    "\n",
    "        # Controlla se il miglior match supera la soglia di similarità\n",
    "        if migliore_match_composito[\"score\"] >= soglia_similarita:\n",
    "            return f\"                       {migliore_match_composito}\"\n",
    "        else:\n",
    "            return \"                       La richiesta non trova corrispondenza con nessuna API. (score: \" + str(migliore_match_composito[\"score\"]) + \")\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Errore durante l'elaborazione: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97063346",
   "metadata": {},
   "source": [
    "# Test secondo caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32bbbab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "     Richiesta utente: cercami i finanziamenti dell'ndg 123456\n",
      "       Frasi estratte: [\"cercami i finanziamenti dell'ndg 123456\"]\n",
      "--- ML\n",
      "       Verbo estratto: ['cercami']\n",
      "  Verbo http predetto: GET\n",
      "               Classi: ['DELETE' 'GET' 'POST' 'PUT']\n",
      "          Probabilità: [9.66234521e-06 9.99464908e-01 5.23321003e-04 2.10856070e-06]\n",
      "  Indice della classe: 1\n",
      "Probabilità del verbo: 0.9994649080912499\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento?tipo=mutuo&ndg=123456', 'verbo_http': 'GET', 'score': np.float32(0.71034634)}\n",
      "--- ML + NLP 2\n",
      "                       {'endpoint': 'api/finanziamento?tipo=mutuo&ndg=123456', 'verbo_http': 'GET', 'score': np.float64(0.739258162066144)}\n",
      "----------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------\n",
      "     Richiesta utente: voglio avviare un nuovo finanziamento\n",
      "       Frasi estratte: ['voglio avviare un nuovo finanziamento']\n",
      "--- ML\n",
      "       Verbo estratto: ['avviare']\n",
      "  Verbo http predetto: DELETE\n",
      "               Classi: ['DELETE' 'GET' 'POST' 'PUT']\n",
      "          Probabilità: [0.52690951 0.01217741 0.4501094  0.01080368]\n",
      "  Indice della classe: 0\n",
      "Probabilità del verbo: 0.5269095112143422\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento', 'verbo_http': 'POST', 'score': np.float32(0.8377562)}\n",
      "--- ML + NLP 2\n",
      "                       {'endpoint': 'api/finanziamento', 'verbo_http': 'POST', 'score': np.float64(0.7989915169332601)}\n",
      "----------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------\n",
      "     Richiesta utente: mi cerchi un finanziamento\n",
      "       Frasi estratte: ['mi cerchi un finanziamento']\n",
      "--- ML\n",
      "       Verbo estratto: ['cerchi']\n",
      "  Verbo http predetto: GET\n",
      "               Classi: ['DELETE' 'GET' 'POST' 'PUT']\n",
      "          Probabilità: [3.30736490e-04 8.76256518e-01 1.65288531e-02 1.06883893e-01]\n",
      "  Indice della classe: 1\n",
      "Probabilità del verbo: 0.8762565175341614\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento?tipo=mutuo&ndg=123456', 'verbo_http': 'GET', 'score': np.float32(0.76548004)}\n",
      "--- ML + NLP 2\n",
      "                       {'endpoint': 'api/finanziamento?tipo=mutuo&ndg=123456', 'verbo_http': 'GET', 'score': np.float64(0.776557653344145)}\n",
      "----------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------\n",
      "     Richiesta utente: ho bisogno di un mutuo per la casa\n",
      "       Frasi estratte: ['ho bisogno di un mutuo per la casa']\n",
      "--- ML\n",
      "       Verbo estratto: ['ho']\n",
      "  Verbo http predetto: PUT\n",
      "               Classi: ['DELETE' 'GET' 'POST' 'PUT']\n",
      "          Probabilità: [9.99328006e-06 4.56887901e-10 5.51749942e-11 9.99990006e-01]\n",
      "  Indice della classe: 3\n",
      "Probabilità del verbo: 0.9999900062078785\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento?ndg=123456', 'verbo_http': 'PUT', 'score': np.float32(0.37362602)}\n",
      "--- ML + NLP 2\n",
      "                       La richiesta non trova corrispondenza con nessuna API. (score: 0.4362624188184197)\n",
      "----------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------\n",
      "     Richiesta utente: vado a comprarmi una pizza\n",
      "       Frasi estratte: ['vado a comprarmi una pizza']\n",
      "--- ML\n",
      "       Verbo estratto: ['vado', 'comprarmi']\n",
      "  Verbo http predetto: GET\n",
      "               Classi: ['DELETE' 'GET' 'POST' 'PUT']\n",
      "          Probabilità: [0.01709176 0.85387262 0.01951738 0.10951823]\n",
      "  Indice della classe: 1\n",
      "Probabilità del verbo: 0.8538726225072255\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento?tipo=mutuo&ndg=123456', 'verbo_http': 'GET', 'score': np.float32(0.12222385)}\n",
      "--- ML + NLP 2\n",
      "                       La richiesta non trova corrispondenza con nessuna API. (score: 0.19538872196847312)\n",
      "----------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------\n",
      "     Richiesta utente: mi crei un finanziamento con ndg 123456 e tipo mutuo\n",
      "       Frasi estratte: ['mi crei un finanziamento con ndg 123456 e tipo mutuo']\n",
      "--- ML\n",
      "       Verbo estratto: ['crei']\n",
      "  Verbo http predetto: POST\n",
      "               Classi: ['DELETE' 'GET' 'POST' 'PUT']\n",
      "          Probabilità: [5.11409317e-05 4.43528438e-03 9.94510627e-01 1.00294798e-03]\n",
      "  Indice della classe: 2\n",
      "Probabilità del verbo: 0.9945106267117317\n",
      "--- NLP 2\n",
      "    Similarità coseno: {'endpoint': 'api/finanziamento', 'verbo_http': 'POST', 'score': np.float32(0.6849687)}\n",
      "--- ML + NLP 2\n",
      "                       {'endpoint': 'api/finanziamento', 'verbo_http': 'POST', 'score': np.float64(0.7159228897013551)}\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "esempi_richiesta = [\n",
    "    \"cercami i finanziamenti dell'ndg 123456\",\n",
    "    \"voglio avviare un nuovo finanziamento\",\n",
    "    \"mi cerchi un finanziamento\",\n",
    "    \"ho bisogno di un mutuo per la casa\",\n",
    "    \"vado a comprarmi una pizza\",\n",
    "    \"mi crei un finanziamento con ndg 123456 e tipo mutuo\",\n",
    "]\n",
    "\n",
    "for richiesta in esempi_richiesta:\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(get_api_2(richiesta, tipo_classificatore=\"ML\", include_oggetto=False, ml_weight=0.1, nlp_weight=0.9, soglia_similarita=0.6)),\n",
    "    print(\"----------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bdceee",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- Pensare a come gestire l'inserimento di più frasi da parte dell'utente in un'unica richiesta\n",
    "- Migliorare la parte di ML, ad esempio: (Parzialmente fatto, TROVATA UN'ALTERNATIVA CON NLP)\n",
    "  - cercare una libreria che data una parola ti fornisce tutti i sinonimi possibili (o una cosa del genere), potrebbe essere utile per costruire un dataset di input in modo automatico\n",
    "  - ci sono modelli migliore del LogisticRegression? \n",
    "  - trovare una parametrizzazione efficiente per addestrare il modello scelto\n",
    "- Capire come migliorare \"live\" l'algoritmo... renforce learning?\n",
    "- AI può suuggerire le prossime azioni da fare (dettate dal workflow)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
